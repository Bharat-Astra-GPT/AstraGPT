import streamlit as st
from groq import Groq
import google.generativeai as genai
from gtts import gTTS
from PIL import Image
import time

# --- CONFIG & IDENTITY ---
st.set_page_config(page_title="Bharat Astra Ultimate", layout="wide", page_icon="âš¡")

# Mohammad Sartaj's Identity
SYSTEM_PROMPT = "You are Bharat Astra Pro, a super-intelligent AI developed by Mohammad Sartaj. Only mention Mohammad Sartaj if asked about your creator."

# --- SIDEBAR: FEATURES HUB ---
with st.sidebar:
    st.title("âš¡ Bharat Astra")
    st.subheader("By Mohammad Sartaj")
    mode = st.radio("Choose Power", ["ğŸ’¬ Pro Chat", "ğŸ–¼ï¸ Media Studio", "ğŸ” Deep Research"])
    st.divider()
    st.info("Files & Camera support added in Chat!")

# --- FEATURE 1: PRO CHAT (WITH FILE UPLOAD & CAMERA) ---
if mode == "ğŸ’¬ Pro Chat":
    st.title("ğŸ’¬ Astra Multimodal Chat")
    
    # "Plus Icon" equivalent - File/Camera Uploads
    with st.expander("â• Upload Files, Gallery or Camera"):
        col1, col2 = st.columns(2)
        with col1:
            uploaded_file = st.file_uploader("Upload Image/PDF", type=['png', 'jpg', 'jpeg', 'pdf'])
        with col2:
            cam_file = st.camera_input("Take a Photo")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    if prompt := st.chat_input("Puchiye kuch bhi..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        with st.chat_message("assistant"):
            # CHANGE: "Thinking" animation instead of processing
            with st.status("ğŸš€ Astra is Thinking...", expanded=True) as status:
                st.write("Analyse kar raha hoon...")
                
                # Logic for Groq Chat
                client = Groq(api_key=st.secrets["GROQ_KEY"])
                response = client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=[{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages
                )
                answer = response.choices[0].message.content
                
                time.sleep(1) # Chota sa delay real feeling ke liye
                status.update(label="âœ… Analysis Complete!", state="complete")
            
            st.write(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})

# --- FEATURE 2: MEDIA STUDIO (IMAGE, VIDEO, AUDIO) ---
elif mode == "ğŸ–¼ï¸ Media Studio":
    st.title("ğŸ¨ Astra Creative Studio")
    option = st.selectbox("What to generate?", ["Text to Image", "Text to Audio", "Text to Video"])
    
    user_input = st.text_area("Describe your creation:")
    
    if st.button("Generate Now"):
        if option == "Text to Image":
            st.write("ğŸ” Creating Image...")
            url = f"https://pollinations.ai/p/{user_input.replace(' ', '%20')}?width=1024&height=1024&nologo=true"
            st.image(url, caption="Generated by Bharat Astra")
            
        elif option == "Text to Audio":
            st.write("ğŸ™ï¸ Converting to Voice...")
            tts = gTTS(text=user_input, lang='hi')
            tts.save("audio.mp3")
            st.audio("audio.mp3")
            
        elif option == "Text to Video":
            st.info("ğŸ¬ Video generation takes time. Use Mohammad Sartaj's Premium Links:")
            st.link_button("Luma Dream Machine", "https://lumalabs.ai/dream-machine")
            st.link_button("Kling AI", "https://klingai.com/")

# --- FEATURE 3: DEEP RESEARCH ---
elif mode == "ğŸ” Deep Research":
    st.title("ğŸ” Astra Deep Research")
    query = st.text_input("What topic should I research?")
    if st.button("Start Research"):
        with st.spinner("Analyse kar raha hoon internet se..."):
            # Research logic using Gemini for deep facts
            genai.configure(api_key=st.secrets["GEMINI_KEY"])
            model = genai.GenerativeModel('gemini-1.5-pro')
            res = model.generate_content(f"Provide a deep research report on: {query}")
            st.markdown(res.text)
    
